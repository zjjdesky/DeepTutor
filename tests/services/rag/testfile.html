<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>深度学习基础 - 测试文档</title>
</head>
<body>
    <header>
        <h1>深度学习基础教程</h1>
        <p>本文档用于RAG管道测试</p>
    </header>

    <main>
        <article>
            <h2>什么是深度学习？</h2>
            <p>深度学习（Deep Learning）是机器学习的一个分支，它使用多层神经网络来学习数据的层次化表示。深度学习在图像识别、自然语言处理和语音识别等领域取得了突破性进展。</p>

            <h3>神经网络的基本组成</h3>
            <ul>
                <li><strong>输入层</strong>：接收原始数据</li>
                <li><strong>隐藏层</strong>：进行特征提取和转换</li>
                <li><strong>输出层</strong>：产生最终预测结果</li>
            </ul>

            <h3>常见的深度学习模型</h3>
            <table border="1">
                <thead>
                    <tr>
                        <th>模型类型</th>
                        <th>主要应用</th>
                        <th>特点</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>卷积神经网络 (CNN)</td>
                        <td>图像分类、目标检测</td>
                        <td>局部感受野、参数共享</td>
                    </tr>
                    <tr>
                        <td>循环神经网络 (RNN)</td>
                        <td>序列建模、时间序列预测</td>
                        <td>处理变长序列、记忆功能</td>
                    </tr>
                    <tr>
                        <td>Transformer</td>
                        <td>自然语言处理、大语言模型</td>
                        <td>自注意力机制、并行计算</td>
                    </tr>
                </tbody>
            </table>

            <h2>深度学习的训练过程</h2>
            <ol>
                <li>数据预处理：清洗、归一化、数据增强</li>
                <li>前向传播：计算预测值</li>
                <li>损失计算：比较预测值与真实值</li>
                <li>反向传播：计算梯度</li>
                <li>参数更新：使用优化器更新权重</li>
            </ol>

            <h3>常用激活函数</h3>
            <p>激活函数为神经网络引入非线性，常用的激活函数包括：</p>
            <ul>
                <li><code>ReLU</code>: f(x) = max(0, x)</li>
                <li><code>Sigmoid</code>: f(x) = 1 / (1 + e^(-x))</li>
                <li><code>Tanh</code>: f(x) = (e^x - e^(-x)) / (e^x + e^(-x))</li>
                <li><code>Softmax</code>: 用于多分类问题的输出层</li>
            </ul>

            <blockquote>
                <p>"深度学习的成功在于其能够自动学习特征表示，而无需人工设计特征。"</p>
                <footer>—— Yann LeCun, Geoffrey Hinton, Yoshua Bengio</footer>
            </blockquote>
        </article>

        <aside>
            <h3>相关资源</h3>
            <nav>
                <ul>
                    <li><a href="https://pytorch.org">PyTorch 官方文档</a></li>
                    <li><a href="https://tensorflow.org">TensorFlow 官方文档</a></li>
                    <li><a href="https://keras.io">Keras 教程</a></li>
                </ul>
            </nav>
        </aside>
    </main>

    <footer>
        <p>© 2024 DeepTutor 测试文件 | 仅用于单元测试</p>
    </footer>
</body>
</html>
